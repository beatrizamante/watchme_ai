Inference Guide
===============

This guide covers how to perform inference with trained models in the WatchMe AI Backend, including person detection with YOLO and person re-identification with OSNet.

Overview
--------

The WatchMe AI Backend supports two main types of inference:

* **YOLO Inference**: Detect and locate people in images/videos
* **OSNet Inference**: Generate embeddings for person re-identification
* **Combined Pipeline**: Full person search workflow

The system is designed for both batch processing and real-time inference scenarios.

YOLO Inference
--------------

Single Image Detection
~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   from src.infrastructure.yolo.core.predict import YOLOPredictor

   def detect_people_in_image():
       predictor = YOLOPredictor()

       # Load image and predict
       results = predictor.predict("path/to/image.jpg")

       # Process results
       for detection in results:
           bbox = detection['bbox']  # [x1, y1, x2, y2]
           confidence = detection['confidence']
           class_name = detection['class_name']
           cropped_image = detection['cropped_image']

           print(f"Found {class_name} at {bbox} with confidence {confidence:.3f}")

       return results

**Using the API endpoint:**

.. code-block:: python

   import requests
   import base64

   # Encode image to base64
   with open('person.jpg', 'rb') as f:
       image_data = base64.b64encode(f.read()).decode()

   # Send to API
   response = requests.post(
       'http://localhost:5000/detect',
       json={'image': image_data}
   )

   detections = response.json()['detections']
   print(f"Found {len(detections)} people")

Batch Image Processing
~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   from pathlib import Path
   import cv2

   def batch_detect_people():
       predictor = YOLOPredictor()
       image_folder = Path("images/")

       results = {}

       for image_path in image_folder.glob("*.jpg"):
           print(f"Processing {image_path.name}...")

           detections = predictor.predict(str(image_path))
           results[image_path.name] = detections

           # Save visualization
           image = cv2.imread(str(image_path))
           for detection in detections:
               bbox = detection['bbox']
               x1, y1, x2, y2 = map(int, bbox)

               # Draw bounding box
               cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)

               # Add confidence text
               conf_text = f"{detection['confidence']:.2f}"
               cv2.putText(image, conf_text, (x1, y1-10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

           # Save result
           output_path = f"results/{image_path.name}"
           cv2.imwrite(output_path, image)

       return results

Video Processing
~~~~~~~~~~~~~~~~

.. code-block:: python

   import cv2

   def process_video():
       predictor = YOLOPredictor()

       # Open video
       cap = cv2.VideoCapture("input_video.mp4")

       # Setup video writer
       fourcc = cv2.VideoWriter_fourcc(*'mp4v')
       fps = int(cap.get(cv2.CAP_PROP_FPS))
       width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
       height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

       out = cv2.VideoWriter('output_video.mp4', fourcc, fps, (width, height))

       frame_number = 0
       total_detections = 0

       while True:
           ret, frame = cap.read()
           if not ret:
               break

           frame_number += 1

           # Process every 5th frame for performance
           if frame_number % 5 == 0:
               detections = predictor.predict_frame(frame)
               total_detections += len(detections)

               # Draw detections
               for detection in detections:
                   bbox = detection['bbox']
                   x1, y1, x2, y2 = map(int, bbox)

                   cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

                   conf_text = f"Person {detection['confidence']:.2f}"
                   cv2.putText(frame, conf_text, (x1, y1-10),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

           # Write frame
           out.write(frame)

           # Progress update
           if frame_number % 100 == 0:
               print(f"Processed {frame_number} frames, found {total_detections} people")

       # Cleanup
       cap.release()
       out.release()

       print(f"Video processing complete. Total detections: {total_detections}")

Real-time Webcam Detection
~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   def real_time_detection():
       predictor = YOLOPredictor()

       # Open webcam
       cap = cv2.VideoCapture(0)

       if not cap.isOpened():
           print("Error: Cannot open webcam")
           return

       print("Press 'q' to quit")

       while True:
           ret, frame = cap.read()
           if not ret:
               break

           # Detect people
           detections = predictor.predict_frame(frame)

           # Draw results
           for detection in detections:
               bbox = detection['bbox']
               x1, y1, x2, y2 = map(int, bbox)
               confidence = detection['confidence']

               # Draw bounding box
               color = (0, 255, 0) if confidence > 0.7 else (0, 255, 255)
               cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)

               # Draw confidence
               text = f"Person {confidence:.2f}"
               cv2.putText(frame, text, (x1, y1-10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

           # Show frame
           cv2.imshow('Real-time Person Detection', frame)

           # Exit on 'q'
           if cv2.waitKey(1) & 0xFF == ord('q'):
               break

       cap.release()
       cv2.destroyAllWindows()

OSNet Inference
---------------

Single Image Embedding
~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   from src.infrastructure.osnet.core.encode import OSNetEncoder

   def create_person_embedding():
       encoder = OSNetEncoder()

       # Load and encode image
       embedding = encoder.encode_single_image("person.jpg")

       print(f"Generated embedding shape: {embedding.shape}")
       print(f"Embedding type: {embedding.dtype}")

       return embedding

**Using the API endpoint:**

.. code-block:: python

   import requests
   import base64

   # Upload image and get embedding
   with open('person.jpg', 'rb') as f:
       image_data = base64.b64encode(f.read()).decode()

   response = requests.post(
       'http://localhost:5000/upload-embedding',
       json={'image': image_data}
   )

   if response.status_code == 200:
       result = response.json()
       embedding = result['embedding']  # Base64 encoded
       shape = result['shape']
       print(f"Embedding created with shape: {shape}")
   else:
       print(f"Error: {response.json()['detail']}")

Batch Embedding Generation
~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   from pathlib import Path
   import numpy as np

   def batch_generate_embeddings():
       encoder = OSNetEncoder()
       image_folder = Path("person_images/")

       embeddings = {}

       for image_path in image_folder.glob("*.jpg"):
           person_id = image_path.stem  # Use filename as ID
           print(f"Processing {person_id}...")

           try:
               embedding = encoder.encode_single_image(str(image_path))
               embeddings[person_id] = embedding
               print(f"✓ Generated embedding for {person_id}")

           except Exception as e:
               print(f"✗ Failed to process {person_id}: {e}")

       # Save embeddings
       np.savez_compressed("person_embeddings.npz", **embeddings)
       print(f"Saved {len(embeddings)} embeddings")

       return embeddings

Person Gallery Creation
~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   import json
   from src._lib.encrypt import encrypt_embedding, decrypt_embedding

   class PersonGallery:
       def __init__(self):
           self.encoder = OSNetEncoder()
           self.gallery = {}

       def add_person(self, person_id, image_path, metadata=None):
           """Add a person to the gallery"""
           try:
               # Generate embedding
               embedding = self.encoder.encode_single_image(image_path)

               # Encrypt embedding
               encrypted_embedding = encrypt_embedding(embedding)

               # Store in gallery
               self.gallery[person_id] = {
                   'embedding': encrypted_embedding,
                   'image_path': image_path,
                   'metadata': metadata or {},
                   'created_at': datetime.now().isoformat()
               }

               print(f"✓ Added {person_id} to gallery")
               return True

           except Exception as e:
               print(f"✗ Failed to add {person_id}: {e}")
               return False

       def save_gallery(self, filepath):
           """Save gallery to file"""
           gallery_data = {}

           for person_id, data in self.gallery.items():
               gallery_data[person_id] = {
                   'embedding': base64.b64encode(data['embedding']).decode(),
                   'image_path': data['image_path'],
                   'metadata': data['metadata'],
                   'created_at': data['created_at']
               }

           with open(filepath, 'w') as f:
               json.dump(gallery_data, f, indent=2)

           print(f"Gallery saved to {filepath}")

       def load_gallery(self, filepath):
           """Load gallery from file"""
           with open(filepath, 'r') as f:
               gallery_data = json.load(f)

           for person_id, data in gallery_data.items():
               self.gallery[person_id] = {
                   'embedding': base64.b64decode(data['embedding']),
                   'image_path': data['image_path'],
                   'metadata': data['metadata'],
                   'created_at': data['created_at']
               }

           print(f"Loaded {len(self.gallery)} people from gallery")

   # Usage
   gallery = PersonGallery()
   gallery.add_person("john_doe", "images/john.jpg", {"name": "John Doe", "age": 30})
   gallery.add_person("jane_smith", "images/jane.jpg", {"name": "Jane Smith", "age": 25})
   gallery.save_gallery("person_gallery.json")

Combined Pipeline
-----------------

Complete Person Search
~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   from src.application.use_cases.predict_person import predict_person_on_stream
   from src._lib.encrypt import decrypt_embedding

   def search_person_in_video():
       # Step 1: Create reference embedding
       encoder = OSNetEncoder()
       reference_embedding = encoder.encode_single_image("reference_person.jpg")

       # Step 2: Search in video
       predictor = YOLOPredictor()
       cap = cv2.VideoCapture("search_video.mp4")

       matches = []
       frame_number = 0

       while True:
           ret, frame = cap.read()
           if not ret:
               break

           frame_number += 1

           # Detect people in frame
           detections = predictor.predict_frame(frame)
